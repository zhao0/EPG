import os
import sys
import re
import json
import time
import random
import argparse
import requests
import datetime
import pytz
from bs4 import BeautifulSoup
from xml.etree import ElementTree as ET
from xml.dom import minidom

# å…¨å±€æ™‚å€è¨­ç½®
TAIPEI_TZ = pytz.timezone('Asia/Taipei')
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def human_like_delay(min_seconds=1, max_seconds=5):
    """äººé¡ä»¿çœŸå»¶é²"""
    delay = random.uniform(min_seconds, max_seconds)
    print(f"â±ï¸ éš¨æ©Ÿå»¶é² {delay:.2f}ç§’")
    time.sleep(delay)

def human_like_typing_effect(text, delay=0.03):
    """äººé¡ä»¿çœŸæ‰“å­—æ•ˆæœ"""
    for char in text:
        print(char, end='', flush=True)
        time.sleep(delay)
    print()

def parse_channel_list():
    """è§£æé »é“æ¸…å–®æª”æ¡ˆå…§å®¹"""
    # éofiiié »é“
    other_channels = [
        "nnews-zh",
        "4gtv-4gtv009",
        "4gtv-4gtv066",
        "4gtv-4gtv040",
        "4gtv-4gtv041",
        "4gtv-4gtv051",
        "4gtv-4gtv052",
        "4gtv-4gtv074",
        "4gtv-4gtv084",
        "4gtv-4gtv085",
        "4gtv-4gtv076",
        "4gtv-4gtv102",
        "4gtv-4gtv103",
        "4gtv-4gtv104",
        "4gtv-4gtv156",
        "4gtv-4gtv158",
        "litv-ftv16",
        "litv-ftv17",
        "litv-longturn01",
        "litv-longturn02",
        "litv-longturn03",
        "litv-longturn11",
        "litv-longturn12",
        "litv-longturn14",
        "litv-longturn18",
        "litv-longturn19",
        "litv-longturn20",
        "litv-longturn21",
        "litv-longturn22",
        "iNEWS",
        "daystar"
    ]
    
    # ç”Ÿæˆofiii13åˆ°ofiii255çš„é€£çºŒé »é“
    ofiii_channels = [f"ofiii{i}" for i in range(13, 256)]
    
    # åˆä½µæ‰€æœ‰é »é“
    channel_list = other_channels + ofiii_channels
    
    print(f"ğŸ“¡ ç¸½å…± {len(channel_list)} å€‹é »é“")
    print(f"   - éofiiié »é“: {len(other_channels)} å€‹")
    print(f"   - ofiiié »é“: {len(ofiii_channels)} å€‹ (ofiii13~ofiii255)")
    
    return channel_list

def fetch_epg_data(channel_id, max_retries=1):
    """ç²å–æŒ‡å®šé »é“çš„é›»è¦–ç¯€ç›®è¡¨æ•¸æ“š"""
    url = f"https://www.ofiii.com/channel/watch/{channel_id}"
    
    for attempt in range(max_retries):
        try:
            # äººé¡ä»¿çœŸ: éš¨æ©Ÿè«‹æ±‚å‰å»¶é²
            if attempt == 0:
                human_like_delay(0.5, 1.5)
            
            print(f"   ğŸ” å˜—è©¦ {attempt+1}/{max_retries}: ç²å– {channel_id}")
            response = requests.get(url, headers=HEADERS, timeout=30)
            response.raise_for_status()
            
            if not response.text.strip():
                print(f"   âš ï¸ éŸ¿æ‡‰å…§å®¹ç‚ºç©º: {channel_id}")
                return None
                
            soup = BeautifulSoup(response.text, 'html.parser')
            script_tag = soup.find('script', id='__NEXT_DATA__')
            
            if script_tag and script_tag.string:
                try:
                    data = json.loads(script_tag.string)
                    print(f"   âœ… æˆåŠŸç²å– {channel_id} çš„æ•¸æ“š")
                    return data
                except json.JSONDecodeError as e:
                    print(f"   âš ï¸ JSONè§£æå¤±æ•—: {channel_id}, {str(e)}")
                    return None
            else:
                print(f"   âš ï¸ æœªæ‰¾åˆ°__NEXT_DATA__æ¨™ç°½: {channel_id}")
                return None
                
        except requests.RequestException as e:
            wait_time = random.uniform(1, 3) * (attempt + 1)
            print(f"   âš ï¸ è«‹æ±‚å¤±æ•— (å˜—è©¦ {attempt+1}/{max_retries}), ç­‰å¾… {wait_time:.2f}ç§’: {str(e)}")
            time.sleep(wait_time)
    
    print(f"   âŒ ç„¡æ³•ç²å– é›»è¦–ç¯€ç›®è¡¨ æ•¸æ“š: {channel_id}")
    return None

def parse_live_epg_data(json_data, channel_id):
    """è§£æç›´æ’­é »é“çš„é›»è¦–ç¯€ç›®è¡¨ JSONæ•¸æ“š"""
    if not json_data:
        return []
    
    programs = []
    try:
        if not json_data.get('props') or not json_data['props'].get('pageProps') or not json_data['props']['pageProps'].get('channel'):
            print(f"   âŒ JSONçµæ§‹ç„¡æ•ˆ: {channel_id}")
            return []
        
        schedule = json_data['props']['pageProps']['channel'].get('Schedule', [])
        
        for item in schedule:
            try:
                start_utc = datetime.datetime.strptime(
                    item['AirDateTime'], "%Y-%m-%dT%H:%M:%SZ"
                ).replace(tzinfo=pytz.utc)
                start_taipei = start_utc.astimezone(TAIPEI_TZ)
                
                duration = datetime.timedelta(seconds=item.get('Duration', 0))
                end_taipei = start_taipei + duration
                
                program_info = item.get('program', {})
                
                programs.append({
                    "channelId": channel_id,
                    "channelName": json_data['props']['pageProps']['channel'].get('title', channel_id),
                    "programName": program_info.get('Title', 'æœªçŸ¥ç¯€ç›®'),
                    "description": program_info.get('Description', ''),
                    "subtitle": program_info.get('SubTitle', ''),
                    "start": start_taipei,
                    "end": end_taipei
                })
                
            except (KeyError, ValueError, TypeError) as e:
                print(f"   âš ï¸ è·³éç„¡æ•ˆçš„ç¯€ç›®æ•¸æ“š: {channel_id}, {str(e)}")
                continue
                
    except (KeyError, TypeError, ValueError) as e:
        print(f"   âŒ è§£æç›´æ’­é›»è¦–ç¯€ç›®è¡¨æ•¸æ“šå¤±æ•—: {str(e)}")
    
    return programs

def parse_vod_epg_data(json_data, channel_id):
    """è§£æé»æ’­é »é“çš„é›»è¦–ç¯€ç›®è¡¨ JSONæ•¸æ“š"""
    if not json_data:
        return []
    
    programs = []
    try:
        if not json_data.get('props') or not json_data['props'].get('pageProps') or not json_data['props']['pageProps'].get('channel'):
            print(f"   âŒ JSONçµæ§‹ç„¡æ•ˆ: {channel_id}")
            return []
        
        channel_data = json_data['props']['pageProps']['channel']
        vod_schedule = channel_data.get('vod_channel_schedule', {})
        
        if not vod_schedule:
            print(f"   âš ï¸ é»æ’­é »é“ {channel_id} æ²’æœ‰ç¯€ç›®è¡¨æ•¸æ“š")
            return []
        
        vod_programs = vod_schedule.get('programs', [])
        
        for item in vod_programs:
            try:
                start_timestamp = item.get('p_start', 0)
                if start_timestamp == 0:
                    continue
                    
                start_taipei = datetime.datetime.fromtimestamp(start_timestamp / 1000, TAIPEI_TZ)
                
                duration_ms = item.get('length', 0)
                duration = datetime.timedelta(milliseconds=duration_ms)
                end_taipei = start_taipei + duration
                
                programs.append({
                    "channelId": channel_id,
                    "channelName": channel_data.get('title', channel_id),
                    "programName": item.get('title', 'æœªçŸ¥ç¯€ç›®'),
                    "description": item.get('vod_channel_description', ''),
                    "subtitle": item.get('subtitle', ''),
                    "start": start_taipei,
                    "end": end_taipei
                })
                
            except (KeyError, ValueError, TypeError) as e:
                print(f"   âš ï¸ è·³éç„¡æ•ˆçš„æ™‚é–“æ ¼å¼: {channel_id}, {str(e)}")
                continue
            
    except (KeyError, TypeError, ValueError) as e:
        print(f"   âŒ è§£æé»æ’­é›»è¦–ç¯€ç›®è¡¨æ•¸æ“šå¤±æ•—: {str(e)}")
    
    return programs

def parse_epg_data(json_data, channel_id):
    """è§£æé›»è¦–ç¯€ç›®è¡¨ JSONæ•¸æ“šï¼Œè‡ªå‹•åˆ¤æ–·ç›´æ’­æˆ–é»æ’­"""
    if not json_data:
        return []
    
    try:
        channel_data = json_data['props']['pageProps']['channel']
        content_type = channel_data.get('content_type', '')
        
        if content_type == 'vod-channel' or channel_data.get('vod_channel_schedule'):
            print(f"   ğŸ“¹ æª¢æ¸¬åˆ°é»æ’­é »é“: {channel_id}")
            return parse_vod_epg_data(json_data, channel_id)
        else:
            print(f"   ğŸ“º æª¢æ¸¬åˆ°ç›´æ’­é »é“: {channel_id}")
            return parse_live_epg_data(json_data, channel_id)
            
    except (KeyError, TypeError, ValueError) as e:
        print(f"   âŒ åˆ¤æ–·é »é“é¡å‹å¤±æ•—: {str(e)}")
        return parse_live_epg_data(json_data, channel_id)

def get_channel_info(json_data, channel_id):
    """å¾JSONæ•¸æ“šä¸­æå–é »é“ä¿¡æ¯"""
    if not json_data:
        return None
    
    try:
        page_props = json_data.get('props', {}).get('pageProps', {})
        channel_data = page_props.get('channel', {})
        
        # ç²å–é »é“åç¨±
        channel_name = channel_data.get('title', channel_id)
        
        # ç²å–é »é“logo
        logo = channel_data.get('picture', '')
        if logo and not logo.startswith("http"):
            logo = f"https://p-cdnstatic.svc.litv.tv/{logo}"
            # å°‡logoè·¯å¾‘ä¸­çš„_tvæ›¿æ›ç‚º_mobileä»¥ç²å–ç§»å‹•ç‰ˆlogo
            if '_tv' in logo:
                logo = logo.replace('_tv', '_mobile')
        
        # ç²å–é »é“æè¿°
        description = channel_data.get('description', '')
        
        return {
            "channelName": channel_name,
            "id": channel_id,
            "logo": logo,
            "description": description
        }
    except Exception as e:
        print(f"   âŒ æå–é »é“ä¿¡æ¯å¤±æ•—: {channel_id}, {str(e)}")
        return None

def get_ofiii_epg():
    """ç²å–æ­é£›é›»è¦–ç¯€ç›®è¡¨"""
    print("="*50)
    human_like_typing_effect("é–‹å§‹ç²å–æ­é£›é›»è¦–ç¯€ç›®è¡¨")
    print("="*50)
    
    # ç²å–é »é“æ¸…å–®
    channels = parse_channel_list()
    if not channels:
        print("âŒ ç„¡æ³•è§£æé »é“æ¸…å–®")
        return [], []
    
    all_channels_info = []
    all_programs = []
    failed_channels = []
    
    # éæ­·æ‰€æœ‰é »é“
    for idx, channel_id in enumerate(channels):
        print(f"\nğŸ“¡ è™•ç†é »é“ [{idx+1}/{len(channels)}]: {channel_id}")
        
        # ç²å–EPGæ•¸æ“š
        json_data = fetch_epg_data(channel_id)
        if not json_data:
            failed_channels.append(channel_id)
            continue
            
        # æå–é »é“ä¿¡æ¯
        channel_info = get_channel_info(json_data, channel_id)
        if channel_info:
            all_channels_info.append(channel_info)
            print(f"   âœ… æˆåŠŸæå–é »é“ä¿¡æ¯: {channel_info['channelName']}")
        else:
            print(f"   âš ï¸ ç„¡æ³•æå–é »é“ä¿¡æ¯: {channel_id}")
        
        # è§£æç¯€ç›®æ•¸æ“š
        programs = parse_epg_data(json_data, channel_id)
        all_programs.extend(programs)
        print(f"   ğŸ“º è§£æåˆ° {len(programs)} å€‹ç¯€ç›®")
            
        # äººé¡ä»¿çœŸ: éš¨æ©Ÿå»¶é²
        if idx < len(channels) - 1:
            human_like_delay(1, 3)
    
    # çµ±è¨ˆçµæœ
    print("\n" + "="*50)
    human_like_typing_effect("æ•¸æ“šç²å–å®Œæˆï¼Œç”Ÿæˆçµ±è¨ˆä¿¡æ¯...")
    print(f"âœ… æˆåŠŸç²å– {len(all_channels_info)} å€‹é »é“ä¿¡æ¯")
    print(f"âœ… æˆåŠŸç²å– {len(all_programs)} å€‹ç¯€ç›®")
    
    if failed_channels:
        print(f"âš ï¸ å¤±æ•—é »é“ ({len(failed_channels)}): {', '.join(failed_channels[:10])}{'...' if len(failed_channels) > 10 else ''}")
    
    # çµ±è¨ˆå„é »é“ç¯€ç›®æ•¸é‡
    channel_counts = {}
    for program in all_programs:
        channel_name = program["channelName"]
        channel_counts[channel_name] = channel_counts.get(channel_name, 0) + 1
    
    print("\nğŸ“Š å„é »é“ç¯€ç›®çµ±è¨ˆ:")
    for channel, count in list(channel_counts.items())[:10]:  # åªé¡¯ç¤ºå‰10å€‹
        print(f"   ğŸ“º {channel}: {count} å€‹ç¯€ç›®")
    
    if len(channel_counts) > 10:
        print(f"   ... é‚„æœ‰ {len(channel_counts) - 10} å€‹é »é“")
    
    print("="*50)
    return all_channels_info, all_programs

def generate_xmltv(channels_info, programs, output_file="ofiii.xml"):
    """ç”ŸæˆXMLTVæ ¼å¼çš„EPGæ•¸æ“šï¼ŒæŒ‰ç…§é »é“ä¸€â†’é »é“ä¸€ç¯€ç›®â†’é »é“äºŒâ†’é »é“äºŒç¯€ç›®çš„é †åºæ’åˆ—"""
    print(f"\nğŸ“„ ç”ŸæˆXMLTVæª”æ¡ˆ: {output_file}")
    human_like_typing_effect("æ­£åœ¨ç”ŸæˆXMLæ ¼å¼çš„ç¯€ç›®è¡¨æ•¸æ“š...")
    
    root = ET.Element("tv", generator="OFIII-EPG-Generator", source="www.ofiii.com")
    
    # æŒ‰ç…§é »é“åç¨±æ’åº
    channels_info_sorted = sorted(channels_info, key=lambda x: x['channelName'])
    
    # å°‡ç¯€ç›®æŒ‰ç…§é »é“åç¨±åˆ†çµ„
    programs_by_channel = {}
    for program in programs:
        channel_name = program['channelName']
        if channel_name not in programs_by_channel:
            programs_by_channel[channel_name] = []
        programs_by_channel[channel_name].append(program)
    
    # æŒ‰ç…§é »é“åç¨±æ’åºç¯€ç›®çµ„
    sorted_channel_names = sorted(programs_by_channel.keys())
    
    # æŒ‰ç…§é »é“ä¸€â†’é »é“ä¸€ç¯€ç›®â†’é »é“äºŒâ†’é »é“äºŒç¯€ç›®çš„é †åºç”ŸæˆXML
    program_count = 0
    channel_count = 0
    
    for channel_name in sorted_channel_names:
        # æ‰¾åˆ°å°æ‡‰çš„é »é“ä¿¡æ¯
        channel_info = None
        for info in channels_info_sorted:
            if info['channelName'] == channel_name:
                channel_info = info
                break
        
        if not channel_info:
            continue
            
        channel_id = channel_info['id']
        
        # æ·»åŠ é »é“å®šç¾©
        channel_elem = ET.SubElement(root, "channel", id=channel_name)  # ä½¿ç”¨é »é“åç¨±ä½œç‚ºID
        ET.SubElement(channel_elem, "display-name", lang="zh").text = channel_name
        
        if channel_info.get('logo'):
            ET.SubElement(channel_elem, "icon", src=channel_info['logo'])
        
        # æ·»åŠ é »é“æè¿°åˆ°XMLTV
        if channel_info.get('description'):
            ET.SubElement(channel_elem, "desc", lang="zh").text = channel_info['description']
        
        channel_count += 1
        
        # æ·»åŠ è©²é »é“çš„æ‰€æœ‰ç¯€ç›®
        channel_programs = programs_by_channel[channel_name]
        # æŒ‰ç…§é–‹å§‹æ™‚é–“æ’åºç¯€ç›®
        channel_programs_sorted = sorted(channel_programs, key=lambda x: x['start'])
        
        for program in channel_programs_sorted:
            try:
                start_time = program['start'].strftime('%Y%m%d%H%M%S %z')
                end_time = program['end'].strftime('%Y%m%d%H%M%S %z')
                
                program_elem = ET.SubElement(
                    root, 
                    "programme", 
                    channel=channel_name,  # ä½¿ç”¨é »é“åç¨±è€ŒéID
                    start=start_time, 
                    stop=end_time
                )
                
                title = program.get('programName', 'æœªçŸ¥ç¯€ç›®')
                ET.SubElement(program_elem, "title", lang="zh").text = title
                
                if program.get('subtitle'):
                    ET.SubElement(program_elem, "sub-title", lang="zh").text = program['subtitle']
                
                if program.get('description'):
                    ET.SubElement(program_elem, "desc", lang="zh").text = program['description']
                
                program_count += 1
            except Exception as e:
                print(f"âš ï¸ è·³éç„¡æ•ˆçš„ç¯€ç›®æ•¸æ“š: {str(e)}")
                continue
    
    # ç”ŸæˆXML
    xml_str = ET.tostring(root, encoding='utf-8').decode('utf-8')
    
    try:
        parsed = minidom.parseString(xml_str)
        pretty_xml = parsed.toprettyxml(indent="  ", encoding='utf-8')
    except Exception as e:
        print(f"âš ï¸ XMLç¾åŒ–å¤±æ•—, ä½¿ç”¨åŸå§‹XML: {str(e)}")
        pretty_xml = xml_str.encode('utf-8')
    
    try:
        with open(output_file, 'wb') as f:
            f.write(pretty_xml)
        
        print(f"âœ… XMLTVæª”æ¡ˆå·²ç”Ÿæˆ: {output_file}")
        print(f"ğŸ“º é »é“æ•¸: {channel_count}")
        print(f"ğŸ“º ç¯€ç›®æ•¸: {program_count}")
        print(f"ğŸ“‹ æ’åˆ—é †åº: é »é“ä¸€ â†’ é »é“ä¸€ç¯€ç›® â†’ é »é“äºŒ â†’ é »é“äºŒç¯€ç›® â†’ ...")
        print(f"ğŸ’¾ æª”æ¡ˆå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
        
        # é¡¯ç¤ºXMLçµæ§‹ç¤ºä¾‹
        print(f"\nğŸ“ XMLçµæ§‹ç¤ºä¾‹:")
        print(f"  <tv>")
        print(f"    <channel id=\"é »é“ä¸€åç¨±\">...</channel>")
        print(f"    <programme channel=\"é »é“ä¸€åç¨±\">...</programme>")
        print(f"    <programme channel=\"é »é“ä¸€åç¨±\">...</programme>")
        print(f"    <channel id=\"é »é“äºŒåç¨±\">...</channel>")
        print(f"    <programme channel=\"é »é“äºŒåç¨±\">...</programme>")
        print(f"    ...")
        print(f"  </tv>")
        
        return True
    except Exception as e:
        print(f"âŒ å„²å­˜XMLæª”æ¡ˆå¤±æ•—: {str(e)}")
        return False

def generate_json_file(channels_info, output_file="ofiii.json"):
    """ç”ŸæˆJSONæ ¼å¼çš„é »é“æ•¸æ“š"""
    print(f"\nğŸ“„ ç”ŸæˆJSONæª”æ¡ˆ: {output_file}")
    human_like_typing_effect("æ­£åœ¨ç”ŸæˆJSONæ ¼å¼çš„é »é“æ•¸æ“š...")
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(channels_info, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSONæª”æ¡ˆå·²ç”Ÿæˆ: {output_file}")
        print(f"ğŸ“º é »é“æ•¸: {len(channels_info)}")
        print(f"ğŸ’¾ æª”æ¡ˆå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
        
        # é¡¯ç¤ºå‰å¹¾å€‹é »é“ä½œç‚ºç¤ºä¾‹
        print("\nğŸ“‹ JSONæª”æ¡ˆå‰5å€‹é »é“ç¤ºä¾‹:")
        for i, channel in enumerate(channels_info[:5]):
            print(f"  {i+1}. {channel['id']}: {channel['channelName']}")
            
        return True
    except Exception as e:
        print(f"âŒ å„²å­˜JSONæª”æ¡ˆå¤±æ•—: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•¸ï¼Œè™•ç†å‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(description='æ­é£›é›»è¦–ç¯€ç›®è¡¨')
    parser.add_argument('--output', type=str, default='output/ofiii.xml', 
                       help='è¼¸å‡ºXMLæª”æ¡ˆè·¯å¾‘ (é»˜èª: output/ofiii.xml)')
    
    args = parser.parse_args()
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ å»ºç«‹è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    try:
        # ç²å–EPGæ•¸æ“š
        channels_info, programs = get_ofiii_epg()
        
        if not channels_info:
            print("âŒ æœªç²å–åˆ°æœ‰æ•ˆé »é“ä¿¡æ¯ï¼Œç„¡æ³•ç”Ÿæˆæª”æ¡ˆ")
            sys.exit(1)
            
        # ç”ŸæˆXMLTVæª”æ¡ˆ
        xml_output = args.output
        if not generate_xmltv(channels_info, programs, xml_output):
            sys.exit(1)
            
        # ç”ŸæˆJSONæª”æ¡ˆ
        json_output = os.path.join(output_dir, "ofiii.json")
        if not generate_json_file(channels_info, json_output):
            print("âš ï¸ JSONæª”æ¡ˆç”Ÿæˆå¤±æ•—ï¼Œä½†XMLå·²æˆåŠŸç”Ÿæˆ")
            
        print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆï¼")
            
    except Exception as e:
        print(f"âŒ ä¸»ç¨‹åºéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
